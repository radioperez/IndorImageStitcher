{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffe8a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk,Image\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d6b26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAffine(matrix, degrees = 10):\n",
    "    print(matrix)\n",
    "    # А11 / А22 близко к единице - perserve scaling\n",
    "    # A11 > 0, A22 > 0 - no reflecting\n",
    "    if matrix[0][0] <= 0 or matrix[1][1] <= 0: return False \n",
    "    angle = matrix[0][1]*180/np.pi\n",
    "    print(angle)\n",
    "    if np.fabs(angle) > degrees: return False\n",
    "    # нужны ограничения для A12 и A21 - restrict shearing - спросить АВ\n",
    "\n",
    "    #нужны ограничения угла наклона - спросить АВ\n",
    "\n",
    "    # Детерминант матрицы преобразования. Если он < 0 то преобразование точно не сохраняет ориентацию,\n",
    "    # Но пусть доп. условие что детерминант обязан быть больше 0.5\n",
    "    determinant = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    print(\"determinant: \", determinant)\n",
    "    \n",
    "    if np.fabs(determinant - 1) > 0.5: return False\n",
    "    else: return True\n",
    "\n",
    "def stitch_pair(origin, addition, distance):\n",
    "    padtop = addition.shape[1] // 4 \n",
    "    padbottom = 0\n",
    "    padleft = 0\n",
    "    padright = 0\n",
    "    origin = cv2.copyMakeBorder(origin, padtop, padbottom, padleft, padright, cv2.BORDER_CONSTANT, (0,0,0))\n",
    "\n",
    "    _, mask = cv2.threshold(cv2.cvtColor(origin, cv2.COLOR_BGR2GRAY), 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    ratio = (origin.shape[0] - padtop - padbottom) / addition.shape[0]\n",
    "    if ratio > 1.5:\n",
    "        #mask[int(padtop+addition.shape[0]):,:] = 0\n",
    "        mask[int(padtop+(origin.shape[0]-padtop-padbottom)/ratio):,:] = 0\n",
    "    cv2.imwrite(\"mask.png\", mask)\n",
    "     \n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_o, desc_o = sift.detectAndCompute(origin, mask)\n",
    "    \n",
    "    _, mask = cv2.threshold(cv2.cvtColor(addition, cv2.COLOR_BGR2GRAY), 10, 255, cv2.THRESH_BINARY)\n",
    "    kp_a, desc_a = sift.detectAndCompute(addition, mask)\n",
    "\n",
    "    kpas = addition.copy()\n",
    "    cv2.drawKeypoints(addition, kp_a, kpas, flags=4)\n",
    "    cv2.imwrite(\"kpas.png\", kpas)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.match(desc_o, desc_a)\n",
    "    # If no matches were found at all\n",
    "    if len(matches)==0: \n",
    "        return False, origin\n",
    "    \n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    out = cv2.drawMatches(origin,kp_o,addition,kp_a,matches[:len(matches)//2],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imwrite(\"matches.png\", out)\n",
    "    \n",
    "    src_points = np.float32([kp_a[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    dst_points = np.float32([kp_o[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "\n",
    "    ### add distance enforcing\n",
    "    # Пусть ширина addition 4.5 м\n",
    "    distance = addition.shape[1] * distance / 4.5\n",
    "    fake_points_src = np.float32([\n",
    "        [[origin.shape[1]//2, 50]],\n",
    "        [[origin.shape[1]//2 - 50, 25]],\n",
    "        [[origin.shape[1]//2 + 50, 25]]\n",
    "    ])\n",
    "    fake_points_dst = np.float32([\n",
    "        [[origin.shape[1]//2, 50 + distance]],\n",
    "        [[origin.shape[1]//2 - 50, 25 + distance]],\n",
    "        [[origin.shape[1]//2 + 50, 25 + distance]]\n",
    "    ])\n",
    "    src_points = np.append(src_points, np.float32(fake_points_src), axis=0)\n",
    "    dst_points = np.append(dst_points, np.float32(fake_points_dst), axis=0)\n",
    "    ###\n",
    "    \n",
    "    h, _ = cv2.estimateAffinePartial2D(src_points, dst_points, cv2.RANSAC)\n",
    "    if checkAffine(h):\n",
    "        flag = True\n",
    "        warp = cv2.warpAffine(addition, h, (origin.shape[1],origin.shape[0]))\n",
    "        _, mask = cv2.threshold(cv2.cvtColor(warp, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "        output = cv2.bitwise_and(origin, origin, mask=mask)\n",
    "        output = output + warp\n",
    "    else:\n",
    "        '''\n",
    "        fake_points_src = np.append(fake_points_src, src_points[:len(src_points)//2], axis=0)\n",
    "        fake_points_dst = np.append(fake_points_dst, dst_points[:len(dst_points)//2], axis=0)\n",
    "        h, _ = cv2.estimateAffinePartial2D(np.float32(fake_points_src), np.float32(fake_points_dst))\n",
    "        flag = False\n",
    "        warp = cv2.warpAffine(addition, h, (origin.shape[1],origin.shape[0]))\n",
    "        _, mask = cv2.threshold(cv2.cvtColor(warp, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "        output = cv2.bitwise_and(origin, origin, mask=mask)\n",
    "        output = output + warp\n",
    "        '''\n",
    "        flag = False\n",
    "        print(\"using origin\")\n",
    "        output = origin.copy()\n",
    "        \n",
    "    \n",
    "    _, mask = cv2.threshold(cv2.cvtColor(output, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x,y,w,h = cv2.boundingRect(contours[0])\n",
    "    \n",
    "    return flag, output[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe60eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPerspective(image, matrix):\n",
    "    print(matrix)\n",
    "    # Первая проверка -- отношение левой и правой стороны после трансформации \n",
    "    points = []\n",
    "    new_points = []\n",
    "    nw = (0,0)\n",
    "    points.append(nw)\n",
    "    ne = (image.shape[1],0)\n",
    "    points.append(ne)\n",
    "    se = (image.shape[1], image.shape[0])\n",
    "    points.append(se)\n",
    "    sw = (0, image.shape[0])\n",
    "    points.append(sw)\n",
    "    \n",
    "    left_original = np.sqrt((nw[0] - sw[0])**2 + (nw[1] - sw[1])**2)\n",
    "    right_original = np.sqrt((ne[0] - se[0])**2 + (ne[1] - se[1])**2)\n",
    "    top_original = np.sqrt((nw[0] - ne[0])**2 + (nw[1]-ne[1])**2)\n",
    "    bottom_original = np.sqrt((sw[0] - se[0])**2 + (sw[1] - se[1])**2)\n",
    "    \n",
    "    for p in points:\n",
    "        alpha = matrix[2][0] * p[0] + matrix[2][1] * p[1] + matrix[2][2]\n",
    "        y = (matrix[1][0] * p[0] + matrix[1][1] * p[1] + matrix[1][2] ) / alpha\n",
    "        x = (matrix[0][0] * p[0] + matrix[0][1] * p[1] + matrix[0][2] ) / alpha\n",
    "        new_points.append((x,y))\n",
    "    new_nw = new_points[0]\n",
    "    new_ne = new_points[1]\n",
    "    new_se = new_points[2]\n",
    "    new_sw = new_points[3]\n",
    "    \n",
    "    ### distance that every point travelled\n",
    "    print(np.sqrt((new_nw[0] - nw[0])**2 + (new_nw[1] - nw[1])**2))\n",
    "    print(np.sqrt((new_ne[0] - ne[0])**2 + (new_ne[1] - ne[1])**2))\n",
    "    print(np.sqrt((new_se[0] - se[0])**2 + (new_se[1] - se[1])**2))\n",
    "    print(np.sqrt((new_sw[0] - sw[0])**2 + (new_sw[1] - sw[1])**2))\n",
    "    \n",
    "    left_converted = np.sqrt((new_nw[0] - new_sw[0])**2 + (new_nw[1] - new_sw[1])**2)\n",
    "    right_converted = np.sqrt((new_ne[0] - new_se[0])**2 + (new_ne[1] - new_se[1])**2)\n",
    "    top_converted = np.sqrt((new_nw[0] - new_ne[0])**2 + (new_nw[1] - new_ne[1])**2)\n",
    "    bottom_converted = np.sqrt((new_sw[0] - new_se[0])**2 + (new_sw[1] - new_se[1])**2)\n",
    "    \n",
    "    # Если модуль (отношение - 1) меньше чем 0.2, то вторая проверка:\n",
    "    print(\"left right ratio: \", left_converted / right_converted)\n",
    "    print(\"top bottom ratio: \", top_converted / bottom_converted)\n",
    "    \n",
    "    # Число обусловленности для плохих преобразований очень большое\n",
    "    print(\"condition: \", np.linalg.cond(matrix[:,:2]))\n",
    "    if np.linalg.cond(matrix[:, :2]) >= 10: return False\n",
    "    if np.fabs(left_converted/right_converted - 1) >= 0.3: return False\n",
    "    if np.fabs(top_converted/bottom_converted - 1) >= 0.3: return False\n",
    "    \n",
    "    # Детерминант матрицы преобразования. Если он < 0 то преобразование точно не сохраняет ориентацию,\n",
    "    # Но пусть доп. условие что детерминант обязан быть больше 0.5\n",
    "    determinant = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    print(\"determinant: \", determinant)\n",
    "    \n",
    "    if (determinant < 0): return False\n",
    "    else: return True\n",
    "\n",
    "def stitch_pair_legacy(origin, addition):\n",
    "    padtop = addition.shape[1]\n",
    "    padbottom = 0\n",
    "    padleft = 0\n",
    "    padright = 0\n",
    "    origin = cv2.copyMakeBorder(origin, padtop, padbottom, padleft, padright, cv2.BORDER_CONSTANT, (0,0,0))\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, mask = cv2.threshold(cv2.cvtColor(origin, cv2.COLOR_BGR2GRAY), 10, 255, cv2.THRESH_BINARY)\n",
    "    kp_o, desc_o = sift.detectAndCompute(origin, mask)\n",
    "    \n",
    "    _, mask = cv2.threshold(cv2.cvtColor(addition, cv2.COLOR_BGR2GRAY), 10, 255, cv2.THRESH_BINARY)\n",
    "    kp_a, desc_a = sift.detectAndCompute(addition, mask)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.match(desc_o, desc_a)\n",
    "    # If no matches were found at all\n",
    "    if len(matches)==0: \n",
    "        return False, origin\n",
    "    \n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    out = cv2.drawMatches(origin,kp_o,addition,kp_a,matches[:len(matches)],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imshow(\"matches\", out)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    src_points = np.float32([kp_a[m.trainIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    dst_points = np.float32([kp_o[m.queryIdx].pt for m in matches]).reshape(-1,1,2)\n",
    "    \n",
    "    h, status = cv2.findHomography(src_points, dst_points, cv2.RANSAC)\n",
    "    if (checkPerspective(addition, h)):\n",
    "        flag = True\n",
    "        warp = cv2.warpPerspective(addition, h, (origin.shape[1],origin.shape[0]))\n",
    "        _, mask = cv2.threshold(cv2.cvtColor(warp, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "        output = cv2.bitwise_and(origin, origin, mask=mask)\n",
    "        output = output + warp\n",
    "    else:\n",
    "        print(\"Using origin\")\n",
    "        output = origin.copy()\n",
    "        flag = False\n",
    "\n",
    "    _, mask = cv2.threshold(cv2.cvtColor(output, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x,y,w,h = cv2.boundingRect(contours[0])\n",
    "    \n",
    "    return flag, output[y:y+h, x:x+w]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "385df4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "paths = filedialog.askopenfilenames(initialdir=\"/home/raz/src/indor/imagestitcher/Images/\", title=\"Select file\",filetypes=((\"PNG\",\".png\"),(\"JPEG\",\".jpg .jpeg\")))\n",
    "print(len(paths))\n",
    "\n",
    "N_IMAGES = len(paths)\n",
    "images = []\n",
    "for p in paths:\n",
    "    images.append(cv2.imread(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "015cdf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[ 9.57333996e-01 -1.68698868e-02  2.67102305e+01]\n",
      " [ 1.68698868e-02  9.57333996e-01  1.07146869e+02]]\n",
      "-0.9665733165400265\n",
      "determinant:  0.9167729729066503\n"
     ]
    }
   ],
   "source": [
    "process = images[0].copy()\n",
    "helper = []\n",
    "helperd = []\n",
    "\n",
    "i = 1\n",
    "dis = 3\n",
    "dd = dis\n",
    "while (i < N_IMAGES):\n",
    "    print(i)\n",
    "    status, process = stitch_pair(process, images[i], dis)\n",
    "    if status:\n",
    "        #cv2.imwrite(\"/home/raz/src/indor/imagestitcher/Images/debug/\"+str(i)+\".png\", process)\n",
    "        i += 1\n",
    "        dis += 3\n",
    "    else:\n",
    "        '''\n",
    "        helper.append(process.copy())\n",
    "        cv2.imwrite(\"/home/raz/src/indor/imagestitcher/Images/debug/\"+str(i)+\".png\", process)\n",
    "        i += 1\n",
    "        dis += 3\n",
    "        '''\n",
    "        helper.append(process.copy())\n",
    "        helperd.append(dd)\n",
    "        cv2.imwrite(\"/home/raz/src/indor/imagestitcher/Images/debug/\"+str(i)+\".png\", process)\n",
    "        i -= 1\n",
    "        dis -= 3\n",
    "        process = images[i].copy()\n",
    "        dd = dis\n",
    "        \n",
    "#process = helper[0]\n",
    "#for i in range(len(helper)):\n",
    "#    _, process = stitch_pair(process, helper[i], helperd[i])\n",
    "\n",
    "cv2.imwrite(\"/home/raz/src/indor/imagestitcher/Images/debug/Result.png\", process)\n",
    "cv2.imshow(\"Result\", process)\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
